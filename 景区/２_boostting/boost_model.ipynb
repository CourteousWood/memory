{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 对TF-IDF降维处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导包与读入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "color = sns.color_palette()\n",
    "%matplotlib inline\n",
    "import jieba.posseg as pseg\n",
    "\n",
    "import jieba\n",
    "import re\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "import random\n",
    "\n",
    "import fasttext\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 读取训练和预测数据\n",
    "data_path = 'data/train_second.csv'\n",
    "df = pd.read_csv(data_path,header = 0)\n",
    "\n",
    "df2 = pd.read_csv('data/train_first.csv', header = 0)\n",
    "\n",
    "df = pd.concat([df], ignore_index=True)\n",
    "\n",
    "test_data_path = 'data/predict_second.csv'\n",
    "test_df = pd.read_csv(test_data_path,header = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=df[:5000]\n",
    "test_df=test_df[:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    2931\n",
       "4    1412\n",
       "3     573\n",
       "2      51\n",
       "1      30\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Score\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4997"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 训练集去重\n",
    "df.drop_duplicates(subset='Discuss', keep='last',inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 加载停用词\n",
    "stop_word = []\n",
    "# stop_words_path = 'dict/stopWordList.txt'\n",
    "\n",
    "# with open(stop_words_path,encoding='utf8') as f:\n",
    "#     for line in f.readlines():\n",
    "#         stop_word.append(line.strip())\n",
    "stop_word.append(' ')\n",
    "# 加载情感词\n",
    "# dict_path = 'dict/dict.dat'\n",
    "# jieba.load_userdict(dict_path)\n",
    "# 字符串清洗，去除停用词\n",
    "def clean_str(stri):    \n",
    "    stri = re.sub(u'[\\s]+|[^\\u4e00-\\u9fa5A-Za-z]+|<br />','',stri)\n",
    "#     stri = re.sub(r'<br />|[\\s+\\.\\!\\/_\\-,$%^*(+\\\"\\']+|[+—【】！，。？、～~@#￥%……&*（）]|[0-9]+', ' ', stri)  # 正则替换\n",
    "\n",
    "    cut_str = jieba.cut(stri.strip())\n",
    "    list_str = [word for word in cut_str if word not in stop_word]\n",
    "    stri = ' '.join(list_str)\n",
    "    return stri\n",
    "\n",
    "df['Discuss'] = df['Discuss'].map(lambda x : clean_str(x))\n",
    "test_df['Discuss'] = test_df['Discuss'].map(lambda x : clean_str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 空白的处理方式\n",
    "def fillnull(x):\n",
    "    if x == '':\n",
    "        return '_na_'\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "\n",
    "df['Discuss'] = df['Discuss'].map(lambda x: fillnull(x))\n",
    "test_df['Discuss'] = test_df['Discuss'].map(lambda x: fillnull(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 辅助函数，评测函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构造fasttext使用的文本\n",
    "def fasttext_data(data,label):\n",
    "    fasttext_data = []\n",
    "    for i in range(len(label)):\n",
    "        sent = data[i]+\"\\t__label__\"+str(int(label[i]))\n",
    "        fasttext_data.append(sent)\n",
    "    with open('train.txt','w') as f:\n",
    "        for data in fasttext_data:\n",
    "            f.write(data)\n",
    "            f.write('\\n')\n",
    "    return 'train.txt'\n",
    "\n",
    "# 得到预测值\n",
    "def get_predict(pred):\n",
    "    score = np.array([1,2,3,4,5])\n",
    "    pred2 = []\n",
    "    for p in pred:\n",
    "        pr = np.sum(p * score)\n",
    "        pred2.append(pr)\n",
    "    return np.array(pred2)\n",
    "\n",
    "# 评测函数\n",
    "def rmsel(true_label,pred):\n",
    "    true_label = np.array(true_label)\n",
    "    pred = np.array(pred)\n",
    "    n = len(true_label)\n",
    "    a = true_label - pred\n",
    "    rmse = np.sqrt(np.sum(a * a)/n)\n",
    "    b = 1/(1+rmse)\n",
    "    return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 朴素贝叶斯、逻辑回归模型融合\n",
    "def lrnb_cv(model1, model2, model3, df, test_df, train_merge):\n",
    "    df = df.sample(frac=1)  # 对行做shuffle\n",
    "    df = df.reset_index(drop=True)\n",
    "    #     # tf-idf向量,目前min_df=1效果最好\n",
    "    #     vec = TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.8,use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "    #     trn_term_doc = vec.fit_transform(df['Discuss'])\n",
    "    #     test_term_doc = vec.transform(test_df['Discuss'])\n",
    "    #     # tf-idf降维\n",
    "    #     tsvd = TruncatedSVD(n_components = 180)\n",
    "    #     trn_term_doc = tsvd.fit_transform(trn_term_doc)\n",
    "    #     test_term_doc = tvsd.transform(test_term_doc)\n",
    "\n",
    "    # 取出模型，lr_model和nb_model\n",
    "    nb_model = model1\n",
    "    lr_model = model2\n",
    "    ri_model = model3\n",
    "    X = trn_term_doc_scale\n",
    "    y = df['Score'].values\n",
    "    lr_pred, nb_pred, ri_pred = [], [], []\n",
    "    folds = list(KFold(n_splits=5, shuffle=True, random_state=2018).split(X, y))\n",
    "\n",
    "    for train_index, test_index in folds:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        # 朴素贝叶斯训练\n",
    "        nb_model.fit(X_train, y_train)\n",
    "        pred_i = nb_model.predict_proba(X_test)\n",
    "        pred_i = get_predict(pred_i)\n",
    "        print('nb cv:', rmsel(y_test, pred_i))\n",
    "        train_merge.loc[test_index, 'nb'] = pred_i  # 将验证集nb预测值进行存储\n",
    "        train_merge.loc[test_index, 'score1'] = y_test  # 将验证集实际结果进行存储\n",
    "        # 逻辑回归训练\n",
    "        lr_model.fit(X_train, y_train)\n",
    "        pred_i = lr_model.predict_proba(X_test)\n",
    "        pred_i = get_predict(pred_i)\n",
    "        print('lr cv:', rmsel(y_test, pred_i))\n",
    "        train_merge.loc[test_index, 'lr'] = pred_i  # 将验证集lr预测值进行存储\n",
    "        train_merge.loc[test_index, 'score2'] = y_test  # 将验证集实际结果进行存储\n",
    "        # 岭回归训练\n",
    "        ri_model.fit(X_train, y_train)\n",
    "        pred_i = ri_model.predict(X_test)\n",
    "        print('ri cv:', rmsel(y_test, pred_i))\n",
    "        train_merge.loc[test_index, 'ri'] = pred_i  # 将验证集ridge预测值进行存储\n",
    "        train_merge.loc[test_index, 'score4'] = y_test  # 将验证集实际结果进行存储\n",
    "\n",
    "        # 朴素贝叶斯预测\n",
    "        nb_predi = nb_model.predict_proba(test_term_doc_scale)\n",
    "        nb_predi = get_predict(nb_predi)\n",
    "        nb_pred.append(nb_predi)\n",
    "        # 逻辑回归预测\n",
    "        lr_predi = lr_model.predict_proba(test_term_doc_scale)\n",
    "        lr_predi = get_predict(lr_predi)\n",
    "        lr_pred.append(lr_predi)\n",
    "        # 岭回归预测\n",
    "        ri_predi = ri_model.predict(test_term_doc_scale)\n",
    "        ri_pred.append(ri_predi)\n",
    "    nb_pred = np.array(nb_pred)\n",
    "    nb_pred = np.mean(nb_pred, axis=0)\n",
    "    lr_pred = np.array(lr_pred)\n",
    "    lr_pred = np.mean(lr_pred, axis=0)\n",
    "    ri_pred = np.array(ri_pred)\n",
    "    ri_pred = np.mean(ri_pred, axis=0)\n",
    "    return nb_pred, lr_pred, ri_pred  # 返回三个模型预测结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fasttext模型\n",
    "def fast_cv(df, test_df, train_merge):\n",
    "    #     df = df.sample(frac=1,random_state=2018)  # 对行做shuffle\n",
    "    #     df = df.reset_index(drop=True)\n",
    "    fast_pred = []\n",
    "    folds = list(KFold(n_splits=5, shuffle=True, random_state=2018).split(X, y))\n",
    "    rmsels = []\n",
    "    for train_index, test_index in folds:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        train_file = fasttext_data(X_train, y_train)\n",
    "        # fasttext训练\n",
    "        classifier = fasttext.supervised(train_file, 'model.model', lr=0.08, dim=256, word_ngrams=3, bucket=200000,\n",
    "                                         loss='hs', label_prefix=\"__label__\")\n",
    "        print(test_index)\n",
    "        print(df.head())\n",
    "        # print(df.loc[test_index,'Discuss'].tolist())\n",
    "\n",
    "        result = classifier.predict_proba(df.loc[test_index, 'Discuss'].astype(\"str\"), k=5)\n",
    "        pred = [[int(sco) * proba for sco, proba in result_i] for result_i in result]\n",
    "        pred = [sum(pred_i) for pred_i in pred]\n",
    "        print('fast cv:', rmsel(y_test, pred))\n",
    "        train_merge.loc[test_index, 'fast'] = pred  # 将验证集fasttext预测值进行存储\n",
    "        train_merge.loc[test_index, 'score3'] = y_test  # 将验证集实际结果进行存储\n",
    "        # fasttext预测\n",
    "        test_result = classifier.predict_proba(test_df['Discuss'].astype(\"str\"), k=5)\n",
    "        fast_predi = [[int(sco) * proba for sco, proba in result_i] for result_i in test_result]\n",
    "        fast_predi = [sum(pred_i) for pred_i in fast_predi]\n",
    "        fast_pred.append(fast_predi)\n",
    "\n",
    "    fast_pred = np.array(fast_pred)\n",
    "    fast_pred = np.mean(fast_pred, axis=0)\n",
    "    return fast_pred  # 返回fasttext模型预测结果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "vec = TfidfVectorizer(ngram_range=(1,2), min_df=1, max_df=0.8,use_idf=1, smooth_idf=1, sublinear_tf=1)\n",
    "trn_term_doc = vec.fit_transform(df['Discuss'])\n",
    "test_term_doc = vec.transform(test_df['Discuss'])\n",
    "# print(type(test_term_doc))\n",
    "# tf-idf降维\n",
    "tsvd = TruncatedSVD(n_components = 180)\n",
    "tsvd.fit(trn_term_doc)\n",
    "trn_term_doc = tsvd.transform(trn_term_doc)\n",
    "test_term_doc = tsvd.transform(test_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4997, 180), (300, 180))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_term_doc.shape  , test_term_doc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 融模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()  # 朴素贝叶斯回归\n",
    "lr_model = LogisticRegression(C=10, class_weight='balanced')  # 逻辑回归模型\n",
    "ri_model = linear_model.Ridge() # 岭回归模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "trn_term_doc_scale = min_max.fit_transform(trn_term_doc)\n",
    "test_term_doc_scale = min_max.transform(test_term_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7\n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.zeros((len(df), 8))\n",
    "train_merge = pd.DataFrame(data)\n",
    "train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb cv: 0.566480254116\n",
      "lr cv: 0.473736244226\n",
      "ri cv: 0.564683902382\n",
      "nb cv: 0.565698996004\n",
      "lr cv: 0.481258709892\n",
      "ri cv: 0.560415370501\n",
      "nb cv: 0.559393781702\n",
      "lr cv: 0.479936337103\n",
      "ri cv: 0.553115318739\n",
      "nb cv: 0.555822924312\n",
      "lr cv: 0.476589852318\n",
      "ri cv: 0.550552207623\n",
      "nb cv: 0.561864620057\n",
      "lr cv: 0.488451397484\n",
      "ri cv: 0.559530351953\n"
     ]
    }
   ],
   "source": [
    "train_merge.columns = ['nb','lr','fast','ri','score1','score2','score3','score4']\n",
    "nb_pred, lr_pred ,ri_pred= lrnb_cv(nb_model, lr_model, ri_model, df, test_df, train_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 4.43519898,  4.43459246]), 300)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_pred[:2],len(nb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>lr</th>\n",
       "      <th>fast</th>\n",
       "      <th>ri</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>score3</th>\n",
       "      <th>score4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.439559</td>\n",
       "      <td>4.107133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.445634</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.437535</td>\n",
       "      <td>4.405524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.635245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.439322</td>\n",
       "      <td>3.822257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.488997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.425786</td>\n",
       "      <td>3.405538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.396246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.433588</td>\n",
       "      <td>2.887204</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.270663</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb        lr  fast        ri  score1  score2  score3  score4\n",
       "0  4.439559  4.107133   0.0  4.445634     3.0     3.0     0.0     3.0\n",
       "1  4.437535  4.405524   0.0  4.635245     3.0     3.0     0.0     3.0\n",
       "2  4.439322  3.822257   0.0  4.488997     5.0     5.0     0.0     5.0\n",
       "3  4.425786  3.405538   0.0  4.396246     5.0     5.0     0.0     5.0\n",
       "4  4.433588  2.887204   0.0  4.270663     5.0     5.0     0.0     5.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   3    5    9   11   15   20   31   34   37   38   49   54   62   63   64\n",
      "   66   71   73   83   89   91  116  119  120  124  130  132  133  139  140\n",
      "  143  144  149  150  151  163  164  165  176  181  186  188  191  194  196\n",
      "  197  198  202  203  206  213  221  230  234  236  237  245  248  254  267\n",
      "  272  276  282  285  288  291  310  314  319  320  326  339  345  349  354\n",
      "  357  361  398  403  405  416  418  422  424  436  439  445  446  450  457\n",
      "  461  463  465  474  481  484  486  499  500  503  504  508  513  524  535\n",
      "  539  544  546  553  563  567  568  575  581  584  585  594  603  606  608\n",
      "  609  615  618  619  620  621  624  628  637  640  644  651  655  656  660\n",
      "  664  665  673  680  682  684  693  694  703  705  706  709  712  727  731\n",
      "  733  745  748  750  757  759  760  762  764  773  778  779  780  785  795\n",
      "  798  815  818  821  833  838  843  846  854  856  864  865  867  871  872\n",
      "  873  875  877  885  887  888  891  892  896  904  908  911  921  922  928\n",
      "  929  930  941  955  958  961  969  976  986  989  993 1000 1004 1011 1012\n",
      " 1015 1016 1017 1022 1024 1030 1031 1044 1046 1052 1056 1057 1058 1062 1064\n",
      " 1065 1067 1085 1086 1087 1089 1094 1098 1099 1106 1110 1111 1116 1117 1123\n",
      " 1138 1144 1145 1155 1163 1170 1173 1188 1190 1196 1199 1200 1204 1207 1208\n",
      " 1214 1224 1231 1233 1234 1237 1245 1247 1248 1250 1254 1255 1266 1270 1286\n",
      " 1293 1294 1298 1304 1308 1319 1327 1329 1339 1340 1341 1343 1348 1349 1370\n",
      " 1376 1378 1379 1384 1386 1398 1402 1404 1411 1413 1416 1417 1425 1428 1439\n",
      " 1440 1445 1449 1454 1458 1464 1489 1490 1491 1499 1504 1516 1521 1526 1528\n",
      " 1529 1530 1531 1538 1541 1552 1559 1566 1568 1569 1570 1584 1593 1596 1608\n",
      " 1611 1616 1619 1624 1627 1633 1634 1635 1646 1648 1660 1661 1679 1688 1695\n",
      " 1704 1708 1713 1716 1728 1729 1735 1741 1751 1757 1758 1761 1771 1774 1776\n",
      " 1778 1782 1784 1786 1792 1804 1805 1808 1824 1839 1845 1854 1857 1861 1862\n",
      " 1868 1871 1875 1876 1877 1878 1889 1890 1893 1900 1904 1907 1913 1917 1922\n",
      " 1924 1925 1927 1930 1934 1935 1940 1950 1951 1955 1958 1961 1966 1978 1982\n",
      " 1984 1986 1987 1989 1990 1993 2005 2007 2011 2013 2018 2019 2026 2027 2029\n",
      " 2031 2040 2043 2047 2051 2053 2056 2065 2070 2082 2084 2091 2096 2103 2114\n",
      " 2115 2117 2124 2139 2146 2150 2155 2157 2160 2164 2167 2177 2183 2185 2191\n",
      " 2194 2199 2201 2202 2203 2205 2208 2209 2210 2218 2220 2222 2225 2236 2245\n",
      " 2250 2251 2262 2268 2269 2279 2284 2289 2290 2292 2294 2300 2301 2311 2313\n",
      " 2320 2321 2322 2323 2330 2335 2337 2346 2352 2363 2364 2373 2374 2386 2387\n",
      " 2388 2399 2401 2403 2407 2427 2438 2439 2442 2462 2468 2470 2473 2483 2490\n",
      " 2503 2506 2507 2510 2514 2520 2528 2531 2533 2534 2541 2546 2551 2558 2562\n",
      " 2573 2574 2578 2580 2586 2587 2614 2617 2623 2629 2635 2656 2659 2672 2675\n",
      " 2680 2684 2686 2688 2689 2699 2713 2716 2730 2738 2745 2747 2748 2749 2760\n",
      " 2763 2769 2777 2782 2783 2791 2799 2801 2802 2805 2815 2818 2819 2824 2827\n",
      " 2830 2831 2833 2838 2864 2865 2867 2873 2875 2883 2896 2900 2902 2906 2917\n",
      " 2918 2919 2921 2922 2923 2926 2938 2949 2951 2952 2988 2990 2993 3001 3002\n",
      " 3003 3005 3012 3014 3016 3025 3041 3042 3046 3054 3059 3062 3064 3069 3077\n",
      " 3088 3100 3109 3111 3117 3120 3122 3125 3130 3138 3141 3142 3148 3153 3156\n",
      " 3160 3162 3173 3184 3188 3193 3198 3201 3202 3203 3204 3205 3208 3209 3215\n",
      " 3217 3218 3223 3225 3227 3230 3246 3249 3251 3255 3257 3259 3261 3265 3267\n",
      " 3272 3275 3276 3285 3286 3287 3301 3302 3303 3305 3320 3321 3337 3340 3349\n",
      " 3354 3357 3360 3362 3366 3370 3374 3375 3377 3386 3387 3393 3394 3411 3418\n",
      " 3421 3422 3427 3431 3435 3439 3441 3443 3457 3458 3459 3460 3465 3468 3469\n",
      " 3473 3499 3500 3502 3503 3504 3505 3506 3507 3510 3514 3521 3526 3533 3539\n",
      " 3548 3557 3559 3561 3562 3563 3572 3584 3587 3588 3593 3597 3604 3611 3612\n",
      " 3618 3622 3643 3646 3650 3652 3655 3659 3664 3665 3667 3668 3675 3679 3680\n",
      " 3683 3684 3685 3697 3710 3711 3714 3722 3726 3728 3735 3737 3744 3746 3749\n",
      " 3750 3754 3758 3759 3781 3785 3794 3800 3803 3810 3815 3820 3826 3833 3837\n",
      " 3839 3857 3860 3863 3867 3870 3874 3875 3889 3890 3893 3903 3910 3913 3925\n",
      " 3927 3928 3935 3943 3945 3947 3957 3958 3961 3964 3969 3970 3973 3977 3980\n",
      " 4000 4004 4013 4015 4016 4029 4032 4038 4044 4054 4058 4059 4068 4070 4073\n",
      " 4082 4086 4087 4091 4092 4093 4094 4101 4106 4111 4115 4119 4120 4125 4131\n",
      " 4142 4153 4156 4167 4169 4179 4181 4183 4200 4201 4204 4206 4212 4222 4228\n",
      " 4229 4232 4233 4253 4255 4260 4265 4271 4274 4277 4291 4299 4311 4312 4313\n",
      " 4315 4316 4318 4320 4323 4324 4330 4334 4335 4346 4351 4353 4354 4361 4366\n",
      " 4378 4379 4381 4386 4393 4395 4400 4410 4417 4422 4424 4437 4439 4440 4441\n",
      " 4443 4448 4453 4454 4458 4463 4464 4466 4468 4482 4494 4498 4503 4512 4513\n",
      " 4530 4541 4543 4547 4548 4559 4560 4562 4568 4570 4571 4572 4578 4583 4587\n",
      " 4591 4593 4598 4604 4615 4617 4629 4632 4636 4645 4660 4661 4672 4673 4674\n",
      " 4678 4690 4691 4694 4699 4704 4712 4713 4715 4717 4728 4733 4734 4744 4762\n",
      " 4772 4774 4783 4805 4807 4814 4825 4826 4832 4833 4836 4847 4852 4860 4864\n",
      " 4865 4866 4869 4877 4879 4880 4889 4893 4895 4900 4908 4913 4916 4920 4923\n",
      " 4932 4947 4958 4962 4967 4970 4974 4981 4990 4995]\n",
      "                                     Id  \\\n",
      "0  4c6d4f1c-3e7e-3653-8cd4-a7aa922f2063   \n",
      "1  b2c9c1ec-c283-380f-a584-bb29895e561e   \n",
      "2  5e0b58f1-35db-3f02-b4b8-ef596da70b17   \n",
      "3  e3f71f80-6224-3d15-86e2-e3c8aa547ba5   \n",
      "5  dbdd8702-4c21-377b-bf0d-2af685885a7f   \n",
      "\n",
      "                                             Discuss  Score  \n",
      "0  景点 没 啥 值得 看 的 山上 都 是 石头 最最 重要 的 是 山上 没有 风 大热天 ...      3  \n",
      "1                           去 厦门 必须 去 的 一个 地方 景色 很 好      4  \n",
      "2           一条 很窄 很窄 的 弄堂 去 的 时候 夜色 已深 有种 恐怖片 的 既 视感      4  \n",
      "3    荷花 市场 的 牌匾 在 后海 那 一块 里面 也 没什么 特别 的 很多 都 是 卖 吃 的      3  \n",
      "5                                           有 好 有 不足      5  \n",
      "fast cv: 0.536599389427\n",
      "[   1    4   10   12   16   27   28   35   36   39   42   48   53   55   56\n",
      "   60   74   75   85   92   94   96   97  109  110  112  115  118  121  128\n",
      "  129  135  136  138  141  145  148  157  166  170  174  175  177  178  179\n",
      "  184  189  190  216  218  247  255  258  277  283  284  287  290  292  294\n",
      "  295  297  304  305  307  308  322  324  325  328  330  333  340  351  353\n",
      "  365  366  368  370  373  374  376  378  379  384  386  390  391  400  414\n",
      "  421  430  431  441  444  451  456  472  478  482  487  489  490  491  505\n",
      "  506  512  518  519  521  527  530  531  532  537  541  548  549  550  564\n",
      "  566  571  573  577  583  587  588  596  597  601  605  623  636  642  643\n",
      "  647  649  650  654  658  661  674  676  685  688  695  710  719  724  743\n",
      "  758  768  775  786  787  790  794  796  801  806  810  819  820  824  828\n",
      "  840  842  848  852  853  855  860  870  876  881  893  895  897  900  901\n",
      "  902  906  912  913  919  924  926  934  936  944  951  953  954  956  959\n",
      "  971  974  980  983  984 1007 1020 1021 1026 1029 1032 1033 1043 1049 1054\n",
      " 1071 1077 1078 1092 1104 1128 1131 1134 1139 1152 1154 1171 1172 1179 1184\n",
      " 1193 1203 1210 1215 1219 1220 1225 1240 1241 1259 1264 1277 1278 1285 1289\n",
      " 1290 1292 1296 1297 1302 1303 1307 1311 1318 1322 1328 1332 1342 1350 1354\n",
      " 1358 1361 1362 1374 1382 1388 1391 1393 1394 1395 1396 1405 1406 1407 1408\n",
      " 1412 1418 1423 1426 1431 1433 1435 1436 1441 1446 1448 1451 1484 1486 1487\n",
      " 1495 1497 1509 1512 1517 1519 1539 1543 1547 1553 1560 1562 1571 1578 1582\n",
      " 1588 1595 1597 1600 1601 1602 1604 1620 1628 1642 1647 1649 1650 1656 1664\n",
      " 1665 1668 1673 1676 1678 1680 1684 1686 1691 1700 1703 1705 1720 1731 1732\n",
      " 1736 1739 1748 1754 1763 1766 1775 1777 1780 1798 1802 1809 1810 1811 1812\n",
      " 1813 1816 1820 1821 1827 1828 1830 1831 1833 1834 1837 1858 1859 1864 1867\n",
      " 1872 1887 1888 1896 1899 1901 1911 1916 1928 1931 1941 1945 1946 1949 1964\n",
      " 1973 1977 1981 1992 1994 1995 1998 2004 2006 2010 2014 2020 2025 2035 2045\n",
      " 2046 2050 2052 2062 2067 2071 2076 2080 2104 2105 2106 2110 2113 2120 2122\n",
      " 2123 2125 2126 2129 2131 2133 2134 2136 2137 2147 2152 2153 2156 2159 2161\n",
      " 2169 2171 2174 2176 2184 2189 2193 2195 2204 2215 2217 2219 2221 2224 2229\n",
      " 2235 2238 2242 2244 2248 2253 2254 2256 2270 2271 2274 2277 2281 2297 2298\n",
      " 2316 2319 2325 2336 2338 2340 2349 2354 2355 2357 2362 2370 2371 2372 2375\n",
      " 2384 2390 2398 2404 2408 2414 2415 2417 2423 2425 2426 2431 2437 2446 2449\n",
      " 2455 2457 2458 2471 2486 2495 2496 2498 2499 2500 2505 2512 2513 2517 2521\n",
      " 2523 2525 2526 2527 2530 2532 2536 2538 2545 2552 2556 2559 2560 2561 2564\n",
      " 2568 2570 2576 2582 2584 2589 2590 2592 2598 2600 2603 2605 2606 2612 2616\n",
      " 2634 2637 2638 2642 2644 2645 2653 2654 2660 2664 2669 2683 2692 2695 2700\n",
      " 2701 2706 2710 2711 2712 2718 2719 2724 2725 2726 2729 2733 2739 2744 2750\n",
      " 2751 2754 2759 2768 2776 2778 2779 2780 2784 2786 2788 2789 2790 2798 2812\n",
      " 2817 2822 2840 2843 2853 2858 2859 2870 2876 2887 2892 2910 2925 2928 2929\n",
      " 2932 2933 2936 2940 2945 2947 2948 2956 2959 2962 2971 2973 2979 2980 2987\n",
      " 2989 3006 3013 3015 3017 3018 3020 3032 3034 3047 3051 3058 3067 3074 3082\n",
      " 3086 3087 3089 3094 3099 3104 3107 3108 3112 3119 3123 3126 3127 3128 3132\n",
      " 3139 3149 3158 3161 3167 3168 3169 3174 3178 3180 3181 3182 3183 3186 3191\n",
      " 3196 3197 3199 3214 3231 3233 3235 3240 3243 3248 3254 3258 3262 3273 3277\n",
      " 3278 3280 3281 3284 3289 3296 3297 3311 3327 3336 3343 3355 3358 3359 3364\n",
      " 3371 3372 3373 3378 3381 3388 3389 3392 3397 3404 3409 3424 3446 3448 3450\n",
      " 3451 3452 3456 3462 3466 3470 3472 3476 3479 3481 3483 3492 3494 3498 3512\n",
      " 3517 3519 3523 3528 3529 3536 3542 3545 3546 3547 3551 3553 3554 3555 3558\n",
      " 3560 3570 3576 3580 3583 3586 3590 3591 3598 3602 3603 3608 3609 3610 3613\n",
      " 3624 3626 3631 3632 3641 3644 3672 3674 3678 3682 3698 3705 3706 3708 3713\n",
      " 3718 3719 3720 3721 3725 3731 3734 3739 3741 3742 3747 3748 3764 3766 3767\n",
      " 3769 3782 3789 3791 3793 3797 3799 3802 3804 3825 3831 3835 3843 3849 3856\n",
      " 3859 3868 3869 3876 3879 3881 3886 3887 3894 3899 3901 3905 3907 3914 3918\n",
      " 3920 3930 3932 3933 3936 3937 3953 3979 3985 3992 4009 4010 4014 4017 4018\n",
      " 4021 4024 4026 4027 4030 4031 4034 4035 4047 4048 4049 4062 4065 4075 4083\n",
      " 4095 4097 4102 4103 4113 4129 4132 4133 4149 4154 4160 4163 4174 4190 4192\n",
      " 4199 4202 4207 4209 4231 4238 4243 4247 4249 4258 4259 4269 4282 4284 4287\n",
      " 4289 4290 4296 4297 4302 4317 4333 4337 4341 4343 4345 4348 4349 4367 4373\n",
      " 4387 4388 4389 4391 4403 4412 4415 4418 4423 4426 4428 4431 4435 4438 4442\n",
      " 4444 4456 4457 4465 4467 4472 4481 4484 4487 4488 4497 4504 4508 4519 4531\n",
      " 4534 4536 4539 4540 4544 4557 4569 4574 4576 4584 4585 4595 4596 4597 4599\n",
      " 4601 4603 4611 4612 4616 4622 4630 4635 4638 4643 4644 4650 4652 4653 4662\n",
      " 4663 4664 4666 4670 4676 4677 4684 4687 4695 4697 4698 4702 4708 4716 4719\n",
      " 4720 4724 4732 4735 4736 4738 4740 4750 4757 4782 4794 4795 4796 4803 4804\n",
      " 4806 4808 4811 4817 4827 4828 4829 4835 4838 4848 4849 4855 4856 4859 4868\n",
      " 4871 4872 4882 4884 4886 4891 4892 4901 4903 4904 4905 4907 4919 4921 4935\n",
      " 4939 4945 4951 4954 4957 4965 4975 4985 4987 4994]\n",
      "                                     Id  \\\n",
      "0  4c6d4f1c-3e7e-3653-8cd4-a7aa922f2063   \n",
      "1  b2c9c1ec-c283-380f-a584-bb29895e561e   \n",
      "2  5e0b58f1-35db-3f02-b4b8-ef596da70b17   \n",
      "3  e3f71f80-6224-3d15-86e2-e3c8aa547ba5   \n",
      "5  dbdd8702-4c21-377b-bf0d-2af685885a7f   \n",
      "\n",
      "                                             Discuss  Score  \n",
      "0  景点 没 啥 值得 看 的 山上 都 是 石头 最最 重要 的 是 山上 没有 风 大热天 ...      3  \n",
      "1                           去 厦门 必须 去 的 一个 地方 景色 很 好      4  \n",
      "2           一条 很窄 很窄 的 弄堂 去 的 时候 夜色 已深 有种 恐怖片 的 既 视感      4  \n",
      "3    荷花 市场 的 牌匾 在 后海 那 一块 里面 也 没什么 特别 的 很多 都 是 卖 吃 的      3  \n",
      "5                                           有 好 有 不足      5  \n",
      "fast cv: 0.541652180363\n",
      "[   6    8   13   14   17   23   25   33   40   44   46   47   59   65   67\n",
      "   68   70   81   86   87   88   90   93   95   98   99  101  104  105  107\n",
      "  113  114  117  131  134  154  155  156  158  160  167  183  199  200  207\n",
      "  212  217  223  224  231  233  235  241  243  246  250  251  260  261  264\n",
      "  266  268  278  281  289  293  298  303  306  309  312  315  317  321  323\n",
      "  334  336  337  341  342  347  350  352  360  362  363  372  375  389  395\n",
      "  397  399  401  402  406  407  419  440  443  466  467  469  477  480  483\n",
      "  485  492  495  502  509  510  511  514  517  522  523  528  534  536  538\n",
      "  545  551  552  554  555  556  578  582  589  591  598  607  612  614  625\n",
      "  627  630  632  634  638  646  668  672  686  692  697  704  707  711  717\n",
      "  722  723  729  736  737  740  751  754  756  761  765  766  767  777  782\n",
      "  783  784  789  792  797  803  804  807  808  811  817  822  825  834  835\n",
      "  836  837  841  845  850  861  866  874  878  882  883  884  894  905  918\n",
      "  920  923  925  935  937  949  957  966  967  973  985  987  990  991  994\n",
      "  997 1009 1010 1014 1018 1027 1028 1038 1041 1047 1055 1061 1074 1081 1082\n",
      " 1088 1093 1107 1109 1113 1118 1121 1125 1126 1127 1133 1136 1140 1141 1143\n",
      " 1146 1149 1150 1151 1153 1157 1162 1167 1169 1176 1180 1182 1189 1191 1195\n",
      " 1198 1218 1226 1243 1251 1252 1262 1263 1267 1268 1269 1271 1275 1283 1284\n",
      " 1287 1291 1305 1310 1313 1331 1335 1345 1346 1351 1360 1364 1366 1371 1373\n",
      " 1380 1387 1390 1392 1401 1409 1420 1443 1450 1452 1453 1455 1457 1460 1461\n",
      " 1463 1466 1467 1471 1473 1475 1479 1482 1485 1488 1498 1501 1502 1503 1507\n",
      " 1508 1511 1514 1515 1518 1527 1535 1536 1544 1546 1548 1556 1557 1573 1575\n",
      " 1576 1577 1580 1585 1591 1592 1599 1607 1610 1612 1626 1629 1630 1636 1637\n",
      " 1638 1639 1641 1645 1651 1653 1654 1655 1657 1662 1663 1666 1669 1692 1696\n",
      " 1698 1715 1717 1718 1725 1730 1742 1743 1744 1749 1750 1760 1762 1767 1783\n",
      " 1785 1787 1788 1790 1793 1795 1799 1801 1818 1823 1825 1847 1849 1851 1852\n",
      " 1865 1873 1882 1884 1894 1898 1902 1905 1919 1920 1923 1933 1936 1937 1939\n",
      " 1944 1947 1948 1952 1956 1997 2003 2009 2012 2016 2017 2023 2032 2033 2037\n",
      " 2038 2042 2048 2055 2057 2059 2060 2066 2073 2079 2086 2087 2089 2099 2100\n",
      " 2107 2108 2109 2111 2112 2118 2140 2144 2168 2170 2173 2192 2207 2212 2213\n",
      " 2227 2230 2231 2241 2247 2249 2255 2259 2260 2261 2276 2280 2285 2287 2291\n",
      " 2302 2308 2310 2312 2314 2315 2317 2328 2332 2334 2339 2347 2356 2365 2367\n",
      " 2376 2380 2382 2393 2396 2400 2405 2411 2412 2430 2432 2434 2435 2436 2440\n",
      " 2441 2445 2447 2448 2451 2454 2456 2460 2465 2472 2477 2485 2488 2491 2492\n",
      " 2494 2497 2509 2519 2535 2539 2542 2543 2547 2550 2553 2554 2567 2571 2575\n",
      " 2577 2579 2594 2610 2615 2618 2622 2627 2647 2651 2652 2658 2665 2670 2676\n",
      " 2677 2681 2685 2687 2690 2691 2708 2714 2715 2720 2721 2723 2728 2735 2736\n",
      " 2741 2752 2753 2756 2757 2761 2762 2766 2772 2773 2775 2796 2800 2804 2807\n",
      " 2811 2814 2823 2829 2832 2835 2837 2842 2844 2846 2856 2857 2860 2862 2866\n",
      " 2868 2874 2878 2881 2891 2897 2898 2899 2904 2913 2914 2915 2934 2941 2942\n",
      " 2954 2955 2957 2960 2961 2963 2964 2975 2985 2992 2996 2997 3000 3007 3008\n",
      " 3022 3024 3029 3040 3045 3048 3049 3050 3055 3057 3065 3071 3073 3085 3096\n",
      " 3110 3113 3116 3118 3124 3129 3137 3152 3163 3175 3187 3194 3206 3219 3220\n",
      " 3222 3228 3234 3252 3253 3256 3263 3266 3269 3294 3298 3307 3308 3316 3317\n",
      " 3318 3323 3328 3329 3330 3331 3338 3339 3344 3348 3353 3356 3367 3379 3385\n",
      " 3396 3399 3401 3402 3407 3408 3412 3416 3420 3432 3437 3440 3447 3454 3455\n",
      " 3471 3478 3480 3486 3490 3491 3495 3501 3520 3522 3531 3532 3535 3540 3543\n",
      " 3544 3550 3552 3564 3569 3581 3585 3589 3592 3596 3601 3606 3607 3614 3617\n",
      " 3620 3621 3623 3627 3636 3639 3651 3661 3666 3670 3673 3687 3694 3699 3716\n",
      " 3717 3723 3727 3733 3736 3738 3768 3770 3772 3773 3776 3777 3787 3790 3795\n",
      " 3796 3805 3807 3811 3812 3817 3819 3824 3828 3830 3842 3846 3847 3851 3853\n",
      " 3855 3861 3864 3865 3872 3873 3888 3892 3898 3900 3902 3911 3915 3916 3917\n",
      " 3919 3921 3922 3924 3926 3938 3939 3941 3949 3950 3955 3959 3960 3971 3974\n",
      " 3984 3989 3991 3997 4001 4002 4020 4022 4023 4040 4043 4055 4060 4064 4069\n",
      " 4071 4076 4079 4085 4089 4105 4107 4112 4114 4118 4122 4123 4124 4128 4136\n",
      " 4139 4141 4147 4150 4161 4165 4166 4175 4184 4185 4191 4194 4195 4213 4215\n",
      " 4220 4223 4227 4244 4254 4261 4264 4280 4292 4294 4295 4298 4307 4314 4319\n",
      " 4332 4338 4344 4347 4352 4356 4365 4374 4380 4382 4385 4390 4394 4397 4399\n",
      " 4401 4406 4408 4413 4414 4425 4427 4430 4452 4459 4460 4461 4469 4470 4473\n",
      " 4483 4486 4492 4493 4501 4502 4506 4507 4511 4514 4515 4517 4520 4521 4528\n",
      " 4532 4537 4538 4546 4549 4556 4558 4575 4581 4590 4592 4594 4600 4606 4610\n",
      " 4614 4619 4621 4623 4624 4625 4628 4631 4641 4642 4649 4651 4654 4655 4656\n",
      " 4669 4675 4686 4692 4705 4707 4710 4721 4727 4741 4743 4746 4749 4756 4760\n",
      " 4761 4763 4765 4768 4771 4773 4775 4778 4781 4784 4788 4792 4798 4809 4813\n",
      " 4815 4816 4820 4821 4822 4823 4824 4837 4840 4841 4842 4845 4854 4858 4873\n",
      " 4876 4878 4897 4898 4899 4902 4912 4926 4933 4937 4940 4946 4948 4955 4956\n",
      " 4960 4966 4969 4971 4979 4986 4989 4992 4993]\n",
      "                                     Id  \\\n",
      "0  4c6d4f1c-3e7e-3653-8cd4-a7aa922f2063   \n",
      "1  b2c9c1ec-c283-380f-a584-bb29895e561e   \n",
      "2  5e0b58f1-35db-3f02-b4b8-ef596da70b17   \n",
      "3  e3f71f80-6224-3d15-86e2-e3c8aa547ba5   \n",
      "5  dbdd8702-4c21-377b-bf0d-2af685885a7f   \n",
      "\n",
      "                                             Discuss  Score  \n",
      "0  景点 没 啥 值得 看 的 山上 都 是 石头 最最 重要 的 是 山上 没有 风 大热天 ...      3  \n",
      "1                           去 厦门 必须 去 的 一个 地方 景色 很 好      4  \n",
      "2           一条 很窄 很窄 的 弄堂 去 的 时候 夜色 已深 有种 恐怖片 的 既 视感      4  \n",
      "3    荷花 市场 的 牌匾 在 后海 那 一块 里面 也 没什么 特别 的 很多 都 是 卖 吃 的      3  \n",
      "5                                           有 好 有 不足      5  \n",
      "fast cv: 0.546333876653\n",
      "[   0    2   19   21   29   30   32   41   43   50   51   57   58   69   76\n",
      "   79   80   82   84  102  103  106  108  122  127  137  146  159  161  168\n",
      "  169  173  182  187  192  195  205  208  209  210  215  219  220  225  228\n",
      "  232  239  240  244  252  253  259  265  271  273  274  275  279  286  296\n",
      "  299  301  302  318  331  335  338  343  344  346  348  364  367  371  377\n",
      "  381  382  387  388  392  404  409  410  413  420  426  427  428  435  438\n",
      "  447  453  459  464  468  475  479  488  496  497  507  520  540  543  547\n",
      "  557  559  561  562  570  576  579  590  592  593  595  599  600  602  604\n",
      "  610  611  613  622  633  639  648  657  662  675  677  678  681  689  690\n",
      "  696  698  700  702  713  714  716  720  721  730  732  734  738  741  744\n",
      "  746  772  774  776  781  788  799  800  802  805  809  813  816  823  831\n",
      "  832  844  849  851  857  858  859  863  886  889  898  909  915  916  927\n",
      "  931  939  945  946  948  964  965  968  970  975  979  981  995  998 1001\n",
      " 1019 1023 1025 1034 1035 1036 1037 1039 1040 1048 1051 1053 1059 1066 1068\n",
      " 1070 1073 1079 1084 1097 1103 1105 1112 1114 1115 1119 1132 1148 1168 1174\n",
      " 1175 1177 1183 1194 1201 1202 1205 1206 1209 1212 1213 1217 1221 1222 1223\n",
      " 1227 1228 1249 1253 1256 1258 1260 1261 1272 1276 1279 1280 1295 1299 1300\n",
      " 1314 1317 1320 1321 1323 1325 1333 1334 1336 1338 1347 1355 1357 1359 1363\n",
      " 1367 1369 1372 1375 1377 1381 1385 1399 1400 1403 1410 1419 1421 1422 1424\n",
      " 1427 1430 1437 1447 1456 1459 1462 1465 1468 1470 1472 1474 1476 1477 1478\n",
      " 1494 1505 1506 1510 1520 1522 1532 1533 1534 1551 1558 1561 1583 1586 1587\n",
      " 1594 1603 1605 1606 1609 1614 1617 1618 1625 1631 1632 1640 1644 1659 1671\n",
      " 1681 1685 1687 1689 1693 1694 1697 1707 1710 1711 1721 1722 1727 1734 1738\n",
      " 1745 1746 1747 1755 1756 1759 1764 1779 1789 1794 1803 1814 1826 1836 1838\n",
      " 1840 1842 1844 1848 1850 1853 1860 1863 1866 1869 1870 1879 1881 1886 1891\n",
      " 1906 1910 1912 1915 1921 1926 1943 1953 1959 1962 1963 1965 1967 1968 1970\n",
      " 1971 1974 1980 1983 1988 1991 1996 1999 2001 2015 2021 2036 2039 2044 2049\n",
      " 2069 2072 2074 2078 2081 2085 2088 2090 2093 2094 2097 2101 2102 2119 2138\n",
      " 2143 2166 2175 2181 2187 2197 2206 2214 2223 2226 2228 2232 2257 2263 2266\n",
      " 2267 2273 2275 2278 2286 2295 2296 2299 2304 2305 2306 2318 2324 2326 2331\n",
      " 2333 2344 2345 2348 2350 2358 2359 2360 2377 2378 2383 2392 2394 2395 2397\n",
      " 2402 2406 2410 2416 2418 2420 2421 2422 2424 2428 2433 2443 2452 2453 2461\n",
      " 2464 2474 2475 2478 2481 2482 2484 2487 2504 2515 2516 2524 2529 2537 2544\n",
      " 2548 2555 2557 2569 2572 2585 2591 2595 2608 2613 2619 2620 2621 2630 2631\n",
      " 2633 2636 2639 2640 2646 2648 2649 2657 2663 2678 2694 2696 2697 2698 2703\n",
      " 2704 2717 2722 2734 2740 2742 2746 2755 2758 2764 2765 2767 2781 2792 2797\n",
      " 2806 2808 2810 2834 2836 2839 2845 2849 2850 2851 2854 2855 2861 2863 2872\n",
      " 2880 2886 2889 2893 2894 2903 2908 2911 2912 2916 2927 2935 2939 2943 2944\n",
      " 2953 2966 2969 2972 2974 2976 2978 2981 2984 2991 2994 2999 3021 3026 3027\n",
      " 3030 3035 3036 3044 3052 3053 3056 3076 3079 3091 3092 3095 3097 3098 3101\n",
      " 3103 3105 3114 3115 3131 3133 3135 3140 3143 3144 3147 3150 3151 3157 3159\n",
      " 3164 3165 3170 3172 3177 3179 3185 3190 3200 3207 3210 3211 3212 3216 3224\n",
      " 3236 3241 3242 3244 3247 3250 3270 3274 3279 3291 3295 3306 3313 3315 3319\n",
      " 3324 3333 3334 3342 3345 3347 3350 3352 3363 3369 3376 3380 3382 3390 3391\n",
      " 3398 3406 3410 3413 3414 3417 3419 3423 3426 3428 3429 3430 3433 3434 3436\n",
      " 3449 3463 3467 3474 3484 3485 3487 3488 3489 3496 3497 3508 3511 3513 3516\n",
      " 3537 3565 3567 3571 3574 3578 3579 3582 3594 3595 3599 3600 3605 3615 3619\n",
      " 3628 3629 3630 3634 3635 3637 3642 3647 3648 3653 3656 3657 3660 3663 3669\n",
      " 3671 3677 3688 3689 3690 3691 3695 3696 3700 3701 3709 3712 3729 3732 3743\n",
      " 3745 3751 3753 3755 3756 3761 3762 3765 3774 3775 3778 3780 3783 3784 3786\n",
      " 3788 3792 3808 3813 3816 3822 3827 3832 3836 3838 3840 3845 3850 3858 3866\n",
      " 3880 3883 3885 3891 3904 3908 3931 3934 3940 3944 3951 3952 3963 3967 3968\n",
      " 3972 3982 3983 3988 3994 3995 3999 4003 4005 4006 4007 4011 4012 4019 4025\n",
      " 4028 4037 4041 4051 4052 4053 4056 4072 4074 4077 4078 4080 4081 4084 4096\n",
      " 4099 4104 4109 4110 4116 4117 4134 4135 4137 4138 4140 4143 4144 4146 4148\n",
      " 4151 4152 4155 4157 4158 4164 4168 4177 4178 4180 4186 4187 4188 4189 4196\n",
      " 4197 4208 4211 4214 4216 4217 4221 4234 4236 4239 4240 4241 4242 4246 4248\n",
      " 4251 4252 4256 4266 4267 4270 4273 4276 4283 4286 4288 4293 4301 4304 4309\n",
      " 4310 4322 4328 4331 4339 4340 4350 4359 4364 4368 4369 4371 4375 4376 4377\n",
      " 4383 4396 4398 4407 4409 4411 4420 4433 4434 4445 4447 4474 4476 4479 4485\n",
      " 4496 4500 4516 4523 4533 4542 4553 4554 4564 4577 4579 4580 4582 4586 4588\n",
      " 4618 4626 4633 4637 4639 4640 4647 4648 4658 4667 4668 4671 4680 4681 4682\n",
      " 4688 4693 4700 4703 4706 4714 4718 4722 4723 4725 4730 4731 4739 4745 4747\n",
      " 4751 4752 4753 4754 4758 4759 4766 4769 4777 4787 4791 4793 4799 4800 4801\n",
      " 4812 4819 4830 4831 4846 4850 4851 4861 4863 4870 4875 4890 4896 4909 4910\n",
      " 4914 4917 4922 4927 4928 4929 4934 4944 4952 4961 4963 4964 4968 4972 4973\n",
      " 4976 4977 4978 4980 4982 4983 4988 4991 4996]\n",
      "                                     Id  \\\n",
      "0  4c6d4f1c-3e7e-3653-8cd4-a7aa922f2063   \n",
      "1  b2c9c1ec-c283-380f-a584-bb29895e561e   \n",
      "2  5e0b58f1-35db-3f02-b4b8-ef596da70b17   \n",
      "3  e3f71f80-6224-3d15-86e2-e3c8aa547ba5   \n",
      "5  dbdd8702-4c21-377b-bf0d-2af685885a7f   \n",
      "\n",
      "                                             Discuss  Score  \n",
      "0  景点 没 啥 值得 看 的 山上 都 是 石头 最最 重要 的 是 山上 没有 风 大热天 ...      3  \n",
      "1                           去 厦门 必须 去 的 一个 地方 景色 很 好      4  \n",
      "2           一条 很窄 很窄 的 弄堂 去 的 时候 夜色 已深 有种 恐怖片 的 既 视感      4  \n",
      "3    荷花 市场 的 牌匾 在 后海 那 一块 里面 也 没什么 特别 的 很多 都 是 卖 吃 的      3  \n",
      "5                                           有 好 有 不足      5  \n",
      "fast cv: 0.549249548642\n",
      "[   7   18   22   24   26   45   52   61   72   77   78  100  111  123  125\n",
      "  126  142  147  152  153  162  171  172  180  185  193  201  204  211  214\n",
      "  222  226  227  229  238  242  249  256  257  262  263  269  270  280  300\n",
      "  311  313  316  327  329  332  355  356  358  359  369  380  383  385  393\n",
      "  394  396  408  411  412  415  417  423  425  429  432  433  434  437  442\n",
      "  448  449  452  454  455  458  460  462  470  471  473  476  493  494  498\n",
      "  501  515  516  525  526  529  533  542  558  560  565  569  572  574  580\n",
      "  586  616  617  626  629  631  635  641  645  652  653  659  663  666  667\n",
      "  669  670  671  679  683  687  691  699  701  708  715  718  725  726  728\n",
      "  735  739  742  747  749  752  753  755  763  769  770  771  791  793  812\n",
      "  814  826  827  829  830  839  847  862  868  869  879  880  890  899  903\n",
      "  907  910  914  917  932  933  938  940  942  943  947  950  952  960  962\n",
      "  963  972  977  978  982  988  992  996  999 1002 1003 1005 1006 1008 1013\n",
      " 1042 1045 1050 1060 1063 1069 1072 1075 1076 1080 1083 1090 1091 1095 1096\n",
      " 1100 1101 1102 1108 1120 1122 1124 1129 1130 1135 1137 1142 1147 1156 1158\n",
      " 1159 1160 1161 1164 1165 1166 1178 1181 1185 1186 1187 1192 1197 1211 1216\n",
      " 1229 1230 1232 1235 1236 1238 1239 1242 1244 1246 1257 1265 1273 1274 1281\n",
      " 1282 1288 1301 1306 1309 1312 1315 1316 1324 1326 1330 1337 1344 1352 1353\n",
      " 1356 1365 1368 1383 1389 1397 1414 1415 1429 1432 1434 1438 1442 1444 1469\n",
      " 1480 1481 1483 1492 1493 1496 1500 1513 1523 1524 1525 1537 1540 1542 1545\n",
      " 1549 1550 1554 1555 1563 1564 1565 1567 1572 1574 1579 1581 1589 1590 1598\n",
      " 1613 1615 1621 1622 1623 1643 1652 1658 1667 1670 1672 1674 1675 1677 1682\n",
      " 1683 1690 1699 1701 1702 1706 1709 1712 1714 1719 1723 1724 1726 1733 1737\n",
      " 1740 1752 1753 1765 1768 1769 1770 1772 1773 1781 1791 1796 1797 1800 1806\n",
      " 1807 1815 1817 1819 1822 1829 1832 1835 1841 1843 1846 1855 1856 1874 1880\n",
      " 1883 1885 1892 1895 1897 1903 1908 1909 1914 1918 1929 1932 1938 1942 1954\n",
      " 1957 1960 1969 1972 1975 1976 1979 1985 2000 2002 2008 2022 2024 2028 2030\n",
      " 2034 2041 2054 2058 2061 2063 2064 2068 2075 2077 2083 2092 2095 2098 2116\n",
      " 2121 2127 2128 2130 2132 2135 2141 2142 2145 2148 2149 2151 2154 2158 2162\n",
      " 2163 2165 2172 2178 2179 2180 2182 2186 2188 2190 2196 2198 2200 2211 2216\n",
      " 2233 2234 2237 2239 2240 2243 2246 2252 2258 2264 2265 2272 2282 2283 2288\n",
      " 2293 2303 2307 2309 2327 2329 2341 2342 2343 2351 2353 2361 2366 2368 2369\n",
      " 2379 2381 2385 2389 2391 2409 2413 2419 2429 2444 2450 2459 2463 2466 2467\n",
      " 2469 2476 2479 2480 2489 2493 2501 2502 2508 2511 2518 2522 2540 2549 2563\n",
      " 2565 2566 2581 2583 2588 2593 2596 2597 2599 2601 2602 2604 2607 2609 2611\n",
      " 2624 2625 2626 2628 2632 2641 2643 2650 2655 2661 2662 2666 2667 2668 2671\n",
      " 2673 2674 2679 2682 2693 2702 2705 2707 2709 2727 2731 2732 2737 2743 2770\n",
      " 2771 2774 2785 2787 2793 2794 2795 2803 2809 2813 2816 2820 2821 2825 2826\n",
      " 2828 2841 2847 2848 2852 2869 2871 2877 2879 2882 2884 2885 2888 2890 2895\n",
      " 2901 2905 2907 2909 2920 2924 2930 2931 2937 2946 2950 2958 2965 2967 2968\n",
      " 2970 2977 2982 2983 2986 2995 2998 3004 3009 3010 3011 3019 3023 3028 3031\n",
      " 3033 3037 3038 3039 3043 3060 3061 3063 3066 3068 3070 3072 3075 3078 3080\n",
      " 3081 3083 3084 3090 3093 3102 3106 3121 3134 3136 3145 3146 3154 3155 3166\n",
      " 3171 3176 3189 3192 3195 3213 3221 3226 3229 3232 3237 3238 3239 3245 3260\n",
      " 3264 3268 3271 3282 3283 3288 3290 3292 3293 3299 3300 3304 3309 3310 3312\n",
      " 3314 3322 3325 3326 3332 3335 3341 3346 3351 3361 3365 3368 3383 3384 3395\n",
      " 3400 3403 3405 3415 3425 3438 3442 3444 3445 3453 3461 3464 3475 3477 3482\n",
      " 3493 3509 3515 3518 3524 3525 3527 3530 3534 3538 3541 3549 3556 3566 3568\n",
      " 3573 3575 3577 3616 3625 3633 3638 3640 3645 3649 3654 3658 3662 3676 3681\n",
      " 3686 3692 3693 3702 3703 3704 3707 3715 3724 3730 3740 3752 3757 3760 3763\n",
      " 3771 3779 3798 3801 3806 3809 3814 3818 3821 3823 3829 3834 3841 3844 3848\n",
      " 3852 3854 3862 3871 3877 3878 3882 3884 3895 3896 3897 3906 3909 3912 3923\n",
      " 3929 3942 3946 3948 3954 3956 3962 3965 3966 3975 3976 3978 3981 3986 3987\n",
      " 3990 3993 3996 3998 4008 4033 4036 4039 4042 4045 4046 4050 4057 4061 4063\n",
      " 4066 4067 4088 4090 4098 4100 4108 4121 4126 4127 4130 4145 4159 4162 4170\n",
      " 4171 4172 4173 4176 4182 4193 4198 4203 4205 4210 4218 4219 4224 4225 4226\n",
      " 4230 4235 4237 4245 4250 4257 4262 4263 4268 4272 4275 4278 4279 4281 4285\n",
      " 4300 4303 4305 4306 4308 4321 4325 4326 4327 4329 4336 4342 4355 4357 4358\n",
      " 4360 4362 4363 4370 4372 4384 4392 4402 4404 4405 4416 4419 4421 4429 4432\n",
      " 4436 4446 4449 4450 4451 4455 4462 4471 4475 4477 4478 4480 4489 4490 4491\n",
      " 4495 4499 4505 4509 4510 4518 4522 4524 4525 4526 4527 4529 4535 4545 4550\n",
      " 4551 4552 4555 4561 4563 4565 4566 4567 4573 4589 4602 4605 4607 4608 4609\n",
      " 4613 4620 4627 4634 4646 4657 4659 4665 4679 4683 4685 4689 4696 4701 4709\n",
      " 4711 4726 4729 4737 4742 4748 4755 4764 4767 4770 4776 4779 4780 4785 4786\n",
      " 4789 4790 4797 4802 4810 4818 4834 4839 4843 4844 4853 4857 4862 4867 4874\n",
      " 4881 4883 4885 4887 4888 4894 4906 4911 4915 4918 4924 4925 4930 4931 4936\n",
      " 4938 4941 4942 4943 4949 4950 4953 4959 4984]\n",
      "                                     Id  \\\n",
      "0  4c6d4f1c-3e7e-3653-8cd4-a7aa922f2063   \n",
      "1  b2c9c1ec-c283-380f-a584-bb29895e561e   \n",
      "2  5e0b58f1-35db-3f02-b4b8-ef596da70b17   \n",
      "3  e3f71f80-6224-3d15-86e2-e3c8aa547ba5   \n",
      "5  dbdd8702-4c21-377b-bf0d-2af685885a7f   \n",
      "\n",
      "                                             Discuss  Score  \n",
      "0  景点 没 啥 值得 看 的 山上 都 是 石头 最最 重要 的 是 山上 没有 风 大热天 ...      3  \n",
      "1                           去 厦门 必须 去 的 一个 地方 景色 很 好      4  \n",
      "2           一条 很窄 很窄 的 弄堂 去 的 时候 夜色 已深 有种 恐怖片 的 既 视感      4  \n",
      "3    荷花 市场 的 牌匾 在 后海 那 一块 里面 也 没什么 特别 的 很多 都 是 卖 吃 的      3  \n",
      "5                                           有 好 有 不足      5  \n",
      "fast cv: 0.541780734344\n"
     ]
    }
   ],
   "source": [
    "# fasttext模型\n",
    "X = df['Discuss'].values\n",
    "y = df['Score'].values\n",
    "fast_pred = fast_cv(df, test_df, train_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>lr</th>\n",
       "      <th>fast</th>\n",
       "      <th>ri</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "      <th>score3</th>\n",
       "      <th>score4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.439559</td>\n",
       "      <td>4.107133</td>\n",
       "      <td>4.190654</td>\n",
       "      <td>4.445634</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.437535</td>\n",
       "      <td>4.405524</td>\n",
       "      <td>4.337659</td>\n",
       "      <td>4.635245</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.439322</td>\n",
       "      <td>3.822257</td>\n",
       "      <td>4.332663</td>\n",
       "      <td>4.488997</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.425786</td>\n",
       "      <td>3.405538</td>\n",
       "      <td>4.273045</td>\n",
       "      <td>4.396246</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.433588</td>\n",
       "      <td>2.887204</td>\n",
       "      <td>4.988243</td>\n",
       "      <td>4.270663</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb        lr      fast        ri  score1  score2  score3  score4\n",
       "0  4.439559  4.107133  4.190654  4.445634     3.0     3.0     3.0     3.0\n",
       "1  4.437535  4.405524  4.337659  4.635245     3.0     3.0     4.0     3.0\n",
       "2  4.439322  3.822257  4.332663  4.488997     5.0     5.0     4.0     5.0\n",
       "3  4.425786  3.405538  4.273045  4.396246     5.0     5.0     3.0     5.0\n",
       "4  4.433588  2.887204  4.988243  4.270663     5.0     5.0     5.0     5.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>lr</th>\n",
       "      <th>fast</th>\n",
       "      <th>ri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.435454</td>\n",
       "      <td>3.924515</td>\n",
       "      <td>4.323929</td>\n",
       "      <td>4.446685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.377445</td>\n",
       "      <td>0.217749</td>\n",
       "      <td>0.145129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.424206</td>\n",
       "      <td>2.678181</td>\n",
       "      <td>4.080437</td>\n",
       "      <td>4.001293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.434294</td>\n",
       "      <td>3.674135</td>\n",
       "      <td>4.173414</td>\n",
       "      <td>4.377254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.435955</td>\n",
       "      <td>3.967249</td>\n",
       "      <td>4.245322</td>\n",
       "      <td>4.437001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.436714</td>\n",
       "      <td>4.190336</td>\n",
       "      <td>4.416258</td>\n",
       "      <td>4.517938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.442868</td>\n",
       "      <td>4.703269</td>\n",
       "      <td>4.988240</td>\n",
       "      <td>4.931377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               nb          lr        fast          ri\n",
       "count  300.000000  300.000000  300.000000  300.000000\n",
       "mean     4.435454    3.924515    4.323929    4.446685\n",
       "std      0.002470    0.377445    0.217749    0.145129\n",
       "min      4.424206    2.678181    4.080437    4.001293\n",
       "25%      4.434294    3.674135    4.173414    4.377254\n",
       "50%      4.435955    3.967249    4.245322    4.437001\n",
       "75%      4.436714    4.190336    4.416258    4.517938\n",
       "max      4.442868    4.703269    4.988240    4.931377"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建测试集\n",
    "data = np.zeros((len(test_df), 4))\n",
    "test = pd.DataFrame(data)\n",
    "feature_columns=['nb','lr', 'fast','ri']\n",
    "test.columns = ['nb','lr', 'fast','ri']\n",
    "test['nb'], test['lr'], test['fast'], test['ri'] =  nb_pred, lr_pred, fast_pred, ri_pred\n",
    "test.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nb</th>\n",
       "      <th>lr</th>\n",
       "      <th>fast</th>\n",
       "      <th>ri</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.435199</td>\n",
       "      <td>4.521176</td>\n",
       "      <td>4.172694</td>\n",
       "      <td>4.753014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.434592</td>\n",
       "      <td>3.905061</td>\n",
       "      <td>4.135437</td>\n",
       "      <td>4.310829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.437468</td>\n",
       "      <td>4.246022</td>\n",
       "      <td>4.187285</td>\n",
       "      <td>4.528860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.436125</td>\n",
       "      <td>3.941207</td>\n",
       "      <td>4.110252</td>\n",
       "      <td>4.420289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.431297</td>\n",
       "      <td>3.865846</td>\n",
       "      <td>4.135437</td>\n",
       "      <td>4.191055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         nb        lr      fast        ri\n",
       "0  4.435199  4.521176  4.172694  4.753014\n",
       "1  4.434592  3.905061  4.135437  4.310829\n",
       "2  4.437468  4.246022  4.187285  4.528860\n",
       "3  4.436125  3.941207  4.110252  4.420289\n",
       "4  4.431297  3.865846  4.135437  4.191055"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# xgb调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor  #GBM algorithm\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 数据准备\n",
    "feature_columns=['nb','lr', 'fast', 'ri']\n",
    "X = train_merge[feature_columns].values\n",
    "y = train_merge['score1'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def modelfit(alg, X, y, useTrainCV=True, early_stopping_rounds=100, cv_folds=5, printFeatureImportance=True):\n",
    "    if useTrainCV:\n",
    "        xgb_param = alg.get_xgb_params()\n",
    "        xgtrain = xgb.DMatrix(X, y)\n",
    "        cvresult = xgb.cv(xgb_param, xgtrain, num_boost_round=alg.get_params()['n_estimators'], nfold=cv_folds,\n",
    "                          metrics='rmse', early_stopping_rounds=early_stopping_rounds)\n",
    "        alg.set_params(n_estimators=cvresult.shape[0])\n",
    "        #         print(cvresult)\n",
    "        print(cvresult.shape[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n"
     ]
    }
   ],
   "source": [
    "# 得到学习熟虑为0.1时的理想决策树目\n",
    "import xgboost as xgb\n",
    "xgb1 = xgb.XGBRegressor(learning_rate=0.1,n_estimators=1000, max_depth=5, min_child_weight=1,\n",
    "                        gamma=0, subsample=0.8,\n",
    "                      objective='reg:linear',scale_pos_weight=1, seed=2018)\n",
    "modelfit(xgb1, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.55868, std: 0.00668, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.55881, std: 0.00674, params: {'max_depth': 3, 'min_child_weight': 3},\n",
       "  mean: 0.55866, std: 0.00668, params: {'max_depth': 3, 'min_child_weight': 5},\n",
       "  mean: 0.55659, std: 0.00671, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.55683, std: 0.00618, params: {'max_depth': 5, 'min_child_weight': 3},\n",
       "  mean: 0.55674, std: 0.00665, params: {'max_depth': 5, 'min_child_weight': 5},\n",
       "  mean: 0.55294, std: 0.00578, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.55308, std: 0.00505, params: {'max_depth': 7, 'min_child_weight': 3},\n",
       "  mean: 0.55322, std: 0.00567, params: {'max_depth': 7, 'min_child_weight': 5}],\n",
       " {'max_depth': 3, 'min_child_weight': 3},\n",
       " 0.5588070625945294)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "score = make_scorer(rmsel)\n",
    "params_test1 = {'max_depth': list(range(3,8,2)), 'min_child_weight': list(range(1,6,2))}\n",
    "xgb2 = xgb.XGBRegressor(learning_rate=0.1,n_estimators=110, max_depth=5, min_child_weight=1, gamma=0, subsample=0.8,\n",
    "                      objective='reg:linear', scale_pos_weight=1, seed=2018)\n",
    "gsearch1 = GridSearchCV(estimator=xgb2, param_grid=params_test1, scoring=score, cv=5)\n",
    "gsearch1.fit(X, y)\n",
    "gsearch1.grid_scores_, gsearch1.best_params_, gsearch1.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562370130555\n",
      "0.563693772737\n",
      "0.55465280922\n",
      "0.551119782619\n",
      "0.557752493859\n",
      "0.557917797798\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "bst = xgb.XGBRegressor(learning_rate=0.01, n_estimators=1100, max_depth=5, min_child_weight=5, gamma=0, subsample=0.8,\n",
    "                       scale_pos_weight=1, seed=2018)\n",
    "xgb_pred = []\n",
    "folds = list(KFold(n_splits=5, shuffle=True, random_state=2018).split(X, y))\n",
    "es = []\n",
    "for tr_index, te_index in folds:\n",
    "    X_train, X_test = X[tr_index], X[te_index]\n",
    "    y_train, y_test = y[tr_index], y[te_index]\n",
    "    bst.fit(X_train, y_train)\n",
    "    y_pred = bst.predict(X_test)\n",
    "    e = rmsel(y_test, y_pred)\n",
    "    print(e)\n",
    "\n",
    "    test_pred = bst.predict(test[feature_columns].values)\n",
    "    xgb_pred.append(test_pred)\n",
    "    es.append(e)\n",
    "print(np.mean(es, axis=0))\n",
    "\n",
    "xgb_pred = np.array(xgb_pred)\n",
    "xgb_pred = np.mean(xgb_pred, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GDBT调参"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.562043308224\n",
      "0.56366935788\n",
      "0.555325104238\n",
      "0.552826753101\n",
      "0.558333125108\n",
      "0.55843952971\n"
     ]
    }
   ],
   "source": [
    "gdbt_model = GradientBoostingRegressor(learning_rate=0.01, n_estimators=1500, min_samples_split=1000,\n",
    "                                       min_samples_leaf=30, max_depth=5, max_features='auto', subsample=0.8,\n",
    "                                       random_state=2018)\n",
    "\n",
    "gdbt_pred = []\n",
    "folds = list(KFold(n_splits=5, shuffle=True, random_state=2018).split(X, y))\n",
    "es = []\n",
    "for tr_index, te_index in folds:\n",
    "    X_train, X_test = X[tr_index], X[te_index]\n",
    "    y_train, y_test = y[tr_index], y[te_index]\n",
    "    gdbt_model.fit(X_train, y_train)\n",
    "    y_pred = gdbt_model.predict(X_test)\n",
    "    e = rmsel(y_test, y_pred)\n",
    "    print(e)\n",
    "\n",
    "    test_pred = gdbt_model.predict(test[feature_columns].values)\n",
    "    gdbt_pred.append(test_pred)\n",
    "    es.append(e)\n",
    "print(np.mean(es, axis=0))\n",
    "gdbt_pred = np.array(gdbt_pred)\n",
    "gdbt_pred = np.mean(gdbt_pred, axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0689497, 4.6754389)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(xgb_pred),  max(xgb_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0697497123718263,\n",
       " 4.0701497188568112,\n",
       " 4.2598052501678474,\n",
       " 4.3610227584838865,\n",
       " 4.3971321582794189,\n",
       " 4.4640867614746096,\n",
       " 4.4806831359863279)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(xgb_pred, 0.01),\n",
    "np.percentile(xgb_pred, 0.015),\n",
    "np.percentile(xgb_pred, 5),\n",
    "np.percentile(xgb_pred, 20),\n",
    "np.percentile(xgb_pred, 30),\n",
    "np.percentile(xgb_pred, 62),\n",
    "np.percentile(xgb_pred, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgb_pred2 = xgb_pred\n",
    "# xgb_pred1 = np.where(xgb_pred1<1.72, 1,xgb_pred1)\n",
    "xgb_pred2 = np.where((xgb_pred2>1.305)&(xgb_pred2<1.28), 2, xgb_pred2)\n",
    "xgb_pred2 = np.where((xgb_pred2<3.3)&(xgb_pred2>1.99), 3, xgb_pred2)\n",
    "xgb_pred2 = np.where((xgb_pred2<4.1)&(xgb_pred2>3.9), 4, xgb_pred2)\n",
    "xgb_pred2 = np.where(xgb_pred2>4.61, 5, xgb_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test['Id'] = test_df['Id']\n",
    "test[['Id', 'xgb_merge2']].to_csv('result/0326-3.csv',index=None,header =None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
